{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVz03XXMKMoz"
   },
   "source": [
    "# Détection d'objet : version simplifiée de YOLO\n",
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1V4aAS7K_Akj83apuMZ2vRjNvjgdgoOCh\" width=500></center>\n",
    "<caption><center> Pipeline de l'algorithme YOLO ([Redmon 2016]) </center></caption>\n",
    "\n",
    "Dans ce TP, nous allons tenter d'aller un peu plus loin que le TP précédent en considérant le problème plus complexe de la détection d'objet, c'est-à-dire de la localisation et la classification conjointe de tous les objets dans l'image ; pour cela nous allons implémenter une version simplifiée de YOLO. Cette version est considérée simplifiée car ne reprenant pas l'intégralité des éléments décrite dans l'article de Redmon (par exemple, sur le choix de l'optimiseur). Une des simplifications principales est également que nous ne considérerons qu'un objet par cellule.\n",
    "\n",
    "Pour rappel, l'idée de YOLO est de découper l'image en une grille de cellules et de réaliser une prédiction de plusieurs boîtes englobantes ainsi qu'une classification par cellule. La vidéo de la cellule suivante rappelle les concepts vus en cours sur YOLO et la détection d'objet en général.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "H-8wH0b0jquq",
    "outputId": "d6b919a0-4c4d-4d27-cda6-8c06ef76f8ca"
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://video.polymny.studio/?v=012cd29c-db98-458f-80d3-6cc5c1da9be3/\", width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nsjid8knt6GZ"
   },
   "source": [
    "Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvf5aZetUIE0",
    "outputId": "7d48d283-327c-4345-a383-ecbcc906f997"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/axelcarlier/wildlife.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZu_3SudL_ll"
   },
   "source": [
    "\n",
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hw4t0vv5uAYv"
   },
   "source": [
    "Définition des différentes variables utiles pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79AGCFLvMUlw"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64 # Dimension des images en entrée du réseau\n",
    "CELL_PER_DIM = 8 # Nombre de cellules en largeur et en hauteur\n",
    "BOX_PER_CELL = 1 # Nombre d'objets par cellule\n",
    "NB_CLASSES = 4 # Nombre de classes du problème\n",
    "PIX_PER_CELL = IMAGE_SIZE/CELL_PER_DIM\n",
    "\n",
    "DATASET_SIZE = 376*4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU3Eihm3wajH"
   },
   "source": [
    "Chargement des données et mise en forme pour le problème de détection. Les données qui posent problème (plus d'une boîte englobante par cellule) sont indiquées et affichées pendant le chargement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0e5cgZooKQg3",
    "outputId": "18c17119-5691-46a5-9a45-622896dd465b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def load_data_detection():\n",
    "  # Chemin vers la base de données\n",
    "  ds_path = \"./wildlife/\"\n",
    "  # Chemins vers les données des 4 différentes classes\n",
    "  paths = [ds_path+\"buffalo/\", ds_path+\"elephant/\", ds_path+\"rhino/\", ds_path+\"zebra/\"]\n",
    "  # Indice d'ajout de données dans les variables x et y \n",
    "  i = 0\n",
    "  # Préparation des structures de données pour x et y\n",
    "  x = np.zeros((DATASET_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "  y = np.zeros((DATASET_SIZE, CELL_PER_DIM, CELL_PER_DIM, NB_CLASSES + 5*BOX_PER_CELL))\n",
    "\n",
    "  # Sauvegarde des largeur/hauteur normalisées de bounding box\n",
    "  widths = []\n",
    "  heights = []\n",
    "\n",
    "  # Parcours des chemins de chacune des classes\n",
    "  for path in paths:\n",
    "\n",
    "    # Parcours des fichiers (classés) du répertoire\n",
    "    dirs = os.listdir(path)\n",
    "    dirs.sort()\n",
    "\n",
    "    for item in dirs:\n",
    "      if os.path.isfile(path + item):\n",
    "        # Extraction de l'extension du fichier \n",
    "        extension = item.split(\".\")[1]\n",
    "\n",
    "        if extension==\"jpg\" or extension==\"JPG\":\n",
    "          # Image : on va remplir la variable x\n",
    "          # Lecture de l'image\n",
    "          img = Image.open(path + item)\n",
    "          #f, e = os.path.splitext(path+item)\n",
    "\n",
    "          # Mise à l'échelle de l'image\n",
    "          img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n",
    "          # Remplissage de la variable x\n",
    "          x[i] = np.asarray(img, dtype=np.int32)\n",
    "\n",
    "        elif extension==\"txt\":\n",
    "          # Texte : coordonnées de boîtes englobantes pour remplir y\n",
    "          labels = open(path + item, \"r\")\n",
    "          # Récupération des lignes du fichier texte\n",
    "          labels = labels.read().split('\\n')\n",
    "          # Si la dernière ligne est vide, la supprimer \n",
    "          if labels[-1]==\"\":\n",
    "            del labels[-1]\n",
    "\n",
    "          err_flag = 0\n",
    "          boxes = []\n",
    "          for label in labels:\n",
    "            # Récupération des informations de la boîte englobante\n",
    "            label = label.split()\n",
    "            # Sauvegarde des largeur/hauteur de boîtes englobantes\n",
    "            widths.append(float(label[3]))\n",
    "            heights.append(float(label[4]))\n",
    "            # Coordonnées du centre de la boîte englobante dans le repère image\n",
    "            cx, cy = float(label[1]) * IMAGE_SIZE, float(label[2]) * IMAGE_SIZE\n",
    "            # Détermination des indices de la cellule dans laquelle tombe le centre\n",
    "            ind_x, ind_y = int(cx // PIX_PER_CELL), int(cy // PIX_PER_CELL)\n",
    "            # YOLO : \"The (x, y) coordinates represent the center of the box relative to the bounds of the grid cell.\"\n",
    "            # On va donc calculer les coordonnées du centre relativement à la cellule dans laquelle il se situe\n",
    "            cx_cell = (cx - ind_x * PIX_PER_CELL) / PIX_PER_CELL\n",
    "            cy_cell = (cy - ind_y * PIX_PER_CELL) / PIX_PER_CELL\n",
    "            # Indice de confiance de la boîte englobante\n",
    "            presence = np.array([1], dtype=\"i\")\n",
    "            # \"One-hot vector\" représentant les probabilités de classe dans la cellule\n",
    "            classes = np_utils.to_categorical(label[0], num_classes=4)\n",
    "            # On range les probabilités de classe à la fin du vecteur ([ BOX 1 ; BOX 2 ; ... ; BOX N ; CLASSES])\n",
    "            y[i, ind_x, ind_y, 5 * BOX_PER_CELL:] = classes\n",
    "\n",
    "            boxes.append([cx, cy, label[3]*IMAGE_SIZE, label[4]*IMAGE_SIZE])\n",
    "            # Détermination de l'indice de la boîte englobante de cellule dans laquelle ranger les informations\n",
    "            ind_box = 0\n",
    "            while y[i, ind_x, ind_y, 5*ind_box] == 1 and ind_box < BOX_PER_CELL - 1:\n",
    "              # Si la boîte d'indice courant est déjà utilisée (présence = 1) \n",
    "              # et que l'on a pas atteint le nombre maximal de boîtes, on passe à la boîte suivante\n",
    "              ind_box = ind_box + 1\n",
    "\n",
    "            if y[i, ind_x, ind_y, 5*ind_box] == 1:\n",
    "              print(\"ERREUR : LA CELLULE CONTIENT DEJA TOUTES LES BOITES DISPONIBLES\")\n",
    "              print(path + item)\n",
    "              err_flag = 1\n",
    "            else:\n",
    "              y[i, ind_x, ind_y, 5*ind_box] = 1\n",
    "              y[i, ind_x, ind_y, 5*ind_box + 1] = cx_cell\n",
    "              y[i, ind_x, ind_y, 5*ind_box + 2] = cy_cell\n",
    "              # Racine carrée de la largeur et hauteur de boîte\n",
    "              y[i, ind_x, ind_y, 5*ind_box + 3] = math.sqrt(float(label[3]))\n",
    "              y[i, ind_x, ind_y, 5*ind_box + 4] = math.sqrt(float(label[4]))\n",
    "\n",
    "          i = i + 1\n",
    "          if err_flag == 1:\n",
    "            img_name = item.split(\".\")[0]\n",
    "            img = Image.open(path + img_name + '.jpg')\n",
    "            # Mise à l'échelle de l'image\n",
    "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            for ind_cell in range(CELL_PER_DIM):                \n",
    "              plt.plot([ind_cell*PIX_PER_CELL, ind_cell*PIX_PER_CELL], [0, IMAGE_SIZE-1], 'k-')\n",
    "              plt.plot([0, IMAGE_SIZE-1], [ind_cell*PIX_PER_CELL, ind_cell*PIX_PER_CELL], 'k-')\n",
    "\n",
    "            #for ind_y in range(CELL_PER_DIM):\n",
    "\n",
    "            for ind_box_plot in range(len(boxes)):\n",
    "              box = boxes[ind_box_plot]\n",
    "              plt.plot(box[0], box[1], 'b.')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "          print(\"extension trouvée : \", extension)\n",
    "\n",
    "  return x, y, widths, heights\n",
    "\n",
    "x,y,w,h = load_data_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_adTA1EuRr5"
   },
   "source": [
    "Partage de la base de données entre données d'entraînement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJN1C21zk9dt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Normalisation des images\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfGul-1mlAyJ",
    "outputId": "37291525-13f8-45cc-fd02-e5f9db3f6849"
   },
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61bRIDNUubDj"
   },
   "source": [
    "Fonction d'affichage des données et des résultats de la détection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "PlqAyYlchCNr",
    "outputId": "3e25bf11-256a-4f61-e8ce-64808c6d8b55"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def print_data_detection(x, y, id=None, image_size=IMAGE_SIZE, mode='gt'):\n",
    "  if id==None:\n",
    "    # Tirage aléatoire d'une image dans la base\n",
    "    num_img = np.random.randint(x.shape[0]) \n",
    "    print(num_img)\n",
    "  else:\n",
    "    num_img = id\n",
    "\n",
    "  img = x[num_img]\n",
    "  lab = y[num_img]\n",
    "\n",
    "  colors = [\"blue\", \"yellow\", \"red\", \"orange\"] # Différentes couleurs pour les différentes classes\n",
    "  classes = [\"Buffalo\", \"Elephant\", \"Rhino\", \"Zebra\"]\n",
    "\n",
    "  boxes = lab[:, :, 1:5]\n",
    "  for ind_x in range(CELL_PER_DIM):\n",
    "    for ind_y in range(CELL_PER_DIM):\n",
    "      box = boxes[ind_x, ind_y]\n",
    "      box[0] = box[0] * PIX_PER_CELL + ind_x * PIX_PER_CELL\n",
    "      box[1] = box[1] * PIX_PER_CELL + ind_y * PIX_PER_CELL\n",
    "      box[2] = box[2]**2 * IMAGE_SIZE\n",
    "      box[3] = box[3]**2 * IMAGE_SIZE\n",
    "      boxes[ind_x, ind_y] = box\n",
    "\n",
    "  # Récupération de toutes les informations des boîtes englobantes\n",
    "  all_presences = np.reshape(lab[:, :, 0], (CELL_PER_DIM*CELL_PER_DIM))\n",
    "  all_boxes = np.reshape(lab[:, :, 1:5], (-1, 4))\n",
    "  all_classes = np.reshape(lab[:, :, 5:9], (-1, 4))\n",
    "\n",
    "  if mode=='pred':\n",
    "    all_presences = 1 / (1 + np.exp(-all_presences))\n",
    "    all_classes = softmax(all_classes, axis=1)\n",
    "\n",
    "  indices_sorted = np.argsort(-all_presences)\n",
    "  #print(all_presences[indices_sorted[0:5]])\n",
    "  #print(all_classes[indices_sorted[0:5]])\n",
    "\n",
    "  # Eliminer toutes les boîtes englobantes dont la probabilité de presence est < 0.5 \n",
    "  seuil = 0.35\n",
    "  all_boxes = all_boxes[np.where(all_presences > seuil)]\n",
    "  all_classes = all_classes[np.where(all_presences > seuil)]\n",
    "  all_presences = all_presences[np.where(all_presences > seuil)]\n",
    "\n",
    "\n",
    "  # Affichage de l'image\n",
    "  plt.imshow(img)\n",
    "  for i in range(all_boxes.shape[0]):\n",
    "\n",
    "    # Détermination de la classe\n",
    "    class_id = np.argmax(all_classes[i])\n",
    "    lab = all_boxes[i]\n",
    "    #print(\"x: {}, y: {}, w: {}, h:{}\".format(ax,ay,width, height))\n",
    "    # Détermination des extrema de la boîte englobante\n",
    "    p_x = [lab[0]-lab[2]/2, lab[0]+lab[2]/2]\n",
    "    p_y = [lab[1]-lab[3]/2, lab[1]+lab[3]/2]\n",
    "    # Affichage de la boîte englobante, dans la bonne couleur\n",
    "    plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
    "    plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
    "    plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
    "    plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id], label=classes[class_id] + \" \" +  str(all_presences[i]))\n",
    "    #plt.title(\"Vérité Terrain : Image {}\".format(num_img, classes[class_id]))\n",
    "  \n",
    "  plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "  plt.show()  \n",
    "\n",
    "\n",
    "print_data_detection(x_train, y_train, image_size=IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrEtJvKAwsB2"
   },
   "source": [
    "\n",
    "<center> <img src=\"https://drive.google.com/uc?id=1_wXc_gTIAr37STaxu3chq1EEjVSKv6a5\" width=500></center>\n",
    "<caption><center> Illustration de la couche de sortie de YOLO. </center></caption>\n",
    "\n",
    "Le modèle que je vous propose ci-dessous n'est qu'une possibilité parmi beaucoup d'autres. L'article de Redmon mentionne une instabilité délicate pendant l'entraînement, ce qui m'a encouragé à choisir une fonction d'activation *elu* (*exponential linear unit*).\n",
    "\n",
    "A vous de compléter la dernière couche pour avoir une sortie de la bonne dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3VZsE7EmRPC"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Dropout, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "def create_model_YOLO(input_shape=(64, 64, 3)):\n",
    "  weight_decay = 0\n",
    "\n",
    "  input_layer = Input(shape=input_shape)\n",
    "\n",
    "  conv1 = Conv2D(32, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
    "  conv1 = Conv2D(32, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  conv1 = Conv2D(32, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  \n",
    "  conv2 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "  conv2 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "  conv2 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "  conv3 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "  conv3 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "  dense4 = Flatten()(pool3)\n",
    "  dense4 = Dense(512, activation='elu',kernel_regularizer=regularizers.l2(weight_decay))(dense4)\n",
    "  dense5 = Dense(512, activation='elu',kernel_regularizer=regularizers.l2(weight_decay))(dense4)\n",
    "  output = Dense(..., activation='linear',kernel_regularizer=regularizers.l2(weight_decay))(dense5) # A COMPLETER\n",
    "  output = Reshape((...))(output) # A COMPLETER\n",
    "\n",
    "  model = Model(input_layer, output)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGi3Yz8Tm4li",
    "outputId": "07a3f572-6027-4531-cf4e-cc58e38cbd10"
   },
   "outputs": [],
   "source": [
    "model = create_model_YOLO()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuCP3Ju8Uo9e"
   },
   "source": [
    "<center> <img src=\"https://drive.google.com/uc?id=1Fbt_Wh_BqZj8Pwt3-04325ItCkQp5G9X\" style=\"width:500;height:300px;\"></center>\n",
    "<caption><center> Détail de la fonction de perte définie dans l'article YOLO v1 </center></caption>\n",
    "\n",
    "Nous arrivons maintenant à la partie délicate de l'implémentation de YOLO : la définition de la fonction de coût à utiliser.\n",
    "\n",
    "Comme nous l'avons vu dans le TP4, lorsque l'on écrit une fonction de coût personnalisée en Keras, il est nécessaire d'utiliser uniquement les fonctions présentes sur la page suivante : \n",
    "https://keras.rstudio.com/articles/backend.html\n",
    "\n",
    "En effet cette fonction de coût qui sera appelée pendant l'entraînement traitera des tenseurs, et non des tableau *numpy*. On doit donc utiliser la librairie Tensorflow qui permet de manipuler les tenseurs.\n",
    "\n",
    "Une partie essentielle de la fonction est déjà écrite : celle qui permet de séparer les données des cellules dites \"vide\" (la vérité terrain ne contient pas de boîte englobante) des \"non vides\".\n",
    "\n",
    "Le détail de la fonction de coût est indiqué ci-dessus : dans l'article $\\lambda_{\\text{coord}} = 5$ et $\\lambda_{\\text{noobj}} = 0.5$. Les $x_i$, $y_i$, $w_i$, $h_i$ correspondent aux coordonnées d'une boîte englobante, $C_i$ correspond à la probabilité de présence d'un objet dans la cellule (fonction sigmoïde appliquée aux éléments de sortie correspondant), et les $p_i(c)$ sont les probabilités de classe (fonction softmax appliquée aux éléments de sortie correspondant).\n",
    "\n",
    "A vous de compléter l'expression des sous-fonctions de la fonction de coût (les fonctions *K.sum*, *K.square*, *K.sigmoid* et *K.softmax* devraient vous suffire !). \n",
    "\n",
    "**NB1 : Notez qu'ici, on choisit pour simplifier l'implémentation d'appliquer les fonction sigmoide et softmax directement dans la fonction de coût aux sorties correspondantes, plutôt que dans la couche de sortie du réseau.**\n",
    "\n",
    "**NB2 : cette implémentation de la fonction de coût est très simplifiée et prend en compte le fait qu'il n'y a qu'une seule boîte englobante par cellule.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uS91oePKnE_K"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Définition de la fonction de perte YOLO\n",
    "def YOLOss(lambda_coord, lambda_noobj, batch_size):\n",
    "\n",
    "    # Partie \"verte\" : sous-partie concernant l'indice de confiance et les \n",
    "    # probabilités de classe dans le cas où une boîte est présente dans la cellule\n",
    "    def box_loss(y_true, y_pred):\n",
    "      return ... # A COMPLETER\n",
    "\n",
    "    # Partie \"bleue\" : sous-partie concernant les coordonnées de boîte englobante \n",
    "    # dans le cas où une boîte est présente dans la cellule\n",
    "    def coord_loss(y_true, y_pred):\n",
    "      return ... # A COMPLETER\n",
    "\n",
    "\n",
    "    # Partie \"rouge\" : sous-partie concernant l'indice de confiance  \n",
    "    # dans le cas où aucune boîte n'est présente dans la cellule\n",
    "    def nobox_loss(y_true, y_pred):\n",
    "      return ... # A COMPLETER\n",
    "\n",
    "\n",
    "    def YOLO_loss(y_true, y_pred):\n",
    "\n",
    "      # On commence par reshape les tenseurs de bs x S x S x (5B+C) à (bsxSxS) x (5B+C)\n",
    "      y_true = K.reshape(y_true, shape=(-1, 9))\n",
    "      y_pred = K.reshape(y_pred, shape=(-1, 9))\n",
    "\n",
    "      # On cherche (dans les labels y_true) les indices des cellules pour lesquelles au moins la première boîte englobante est présente\n",
    "      not_empty = K.greater_equal(y_true[:, 0], 1)      \n",
    "      indices = K.arange(0, K.shape(y_true)[0])\n",
    "      indices_notempty_cells = indices[not_empty]\n",
    "\n",
    "      empty = K.less_equal(y_true[:, 0], 0)\n",
    "      indices_empty_cells = indices[empty]\n",
    "\n",
    "      # On sépare les cellules de y_true et y_pred avec ou sans boîte englobante\n",
    "      y_true_notempty = K.gather(y_true, indices_notempty_cells)\n",
    "      y_pred_notempty = K.gather(y_pred, indices_notempty_cells)\n",
    "\n",
    "      y_true_empty = K.gather(y_true, indices_empty_cells)\n",
    "      y_pred_empty = K.gather(y_pred, indices_empty_cells)\n",
    "\n",
    "      return (box_loss(y_true_notempty, y_pred_notempty) + lambda_coord*coord_loss(y_true_notempty, y_pred_notempty) + lambda_noobj*nobox_loss(y_true_empty, y_pred_empty))/batch_size\n",
    "\n",
    "   \n",
    "    # Return a function\n",
    "    return YOLO_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91QkqtUCZc78",
    "outputId": "9a394576-2554-4e5c-8054-9c6b02dcc6bc"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size=16\n",
    "model = create_model_YOLO()\n",
    "opt = Adam(learning_rate=1e-4)  \n",
    "\n",
    "# Comme l'entraînement est instable, on déclenche une sauvegarde du modèle à chaque fois que\n",
    "# la perte de validation atteint un nouveau minimum\n",
    "model_saver = ModelCheckpoint('tmp/best_weights', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
    "\n",
    "loss=[YOLOss(5, 0.5, batch_size)]\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=opt)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "              epochs=100,\n",
    "              batch_size=batch_size,           \n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks = [model_saver])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIaImTjf1fvF"
   },
   "source": [
    "Test de la version à la fin de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "ZjPnyo6G1b1W",
    "outputId": "6634bd6d-63a1-481e-aece-b172113622e7"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)\n",
    "print_data_detection(x_train, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "X5MKydNv1djI",
    "outputId": "9f22f8b5-df21-4c1b-f529-d53febd9cfbb"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print_data_detection(x_val, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqMHwVaJ1iyN"
   },
   "source": [
    "Test de la meilleure version sauvegardée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRjn1SLn0JL4",
    "outputId": "2b797a0c-fa6a-49bc-ecd4-679d777971d0"
   },
   "outputs": [],
   "source": [
    "model.load_weights('tmp/best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "dfytX2yC1AdY",
    "outputId": "3ac092ad-27aa-4b8d-8188-2654f5486f8f"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)\n",
    "print_data_detection(x_train, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "zBiTzmyu0QqH",
    "outputId": "9e4282a8-3d52-463d-cb19-6166f0fa06d1"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print_data_detection(x_val, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAlNpxA3uxBr"
   },
   "source": [
    "## Chargement de poids d'un réseau déjà entraîné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5DB17gJu4DZ"
   },
   "source": [
    "L'entraînement de YOLO étant très instable, il est possible qu'à l'issue du TP vous n'obteniez pas des résultats très probants. Pour finir ce TP, je vous propose de charger les poids d'un modèle que j'ai entraîné pendant un long moment et de visualiser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Flhlq1874H6F",
    "outputId": "0460acab-c10c-4558-ecf2-c39380f19f81"
   },
   "outputs": [],
   "source": [
    "# Téléchargement des poids\n",
    "!wget https://drive.google.com/uc?id=1PtOtf4Du69Sqzj3oYS2nD1mAoz8n1KgZ -O best_weights.index\n",
    "!wget https://drive.google.com/uc?id=1w9VHJxjOEUIhcJZeUBkIl7ZnTJLYz9kv -O best_weights.data-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9SXVXanSmpe",
    "outputId": "adfd417e-97ea-419a-a73e-d051d3f59475"
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "RCNoAH9grggS",
    "outputId": "30fe951a-2618-4ae7-b5b8-ba431c47642d"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)\n",
    "print_data_detection(x_train, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "qjGN0rbawQVK",
    "outputId": "91d845a8-c3db-4569-aa2a-58f992c8af53"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print_data_detection(x_val, y_pred, image_size=IMAGE_SIZE, mode='pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QQpj1Me7W8K"
   },
   "source": [
    "Les résultats ne sont certes pas parfaits mais on commence à voir apparaître quelques résultats satisfaisants. Le modèle a sur-appris, je n'ai pas intégré l'augmentation de données dans cet entraînement (cela aurait pu aider) mais on peut voir sur les quelques exemples ci-dessous que certaines des images sont plutôt bien prédites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "33ox7P-e4SJ2",
    "outputId": "ec77327f-9141-49d3-c722-dede71e9e441"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "\n",
    "print_data_detection(x_val, y_pred, id=81, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=28, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=37, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=220, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=214, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=193, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=39, image_size=IMAGE_SIZE, mode='pred')\n",
    "print_data_detection(x_val, y_pred, id=108, image_size=IMAGE_SIZE, mode='pred')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLO_simplifié.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
